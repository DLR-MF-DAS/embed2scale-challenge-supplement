{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed2Scale challenge \"mean\" baselilne\n",
    "\n",
    "This notebook creates baseline embeddings by bilinear interpolation and averaging of the modalities.\n",
    "\n",
    "We use the E2SChallengeDataset to load the data. The datacubes of the challenge data are of shapes (1, 4, 27, 264, 264), (number of samples, number of timesteps, number of channels, height, width).\n",
    "\n",
    "The embedding works as follow:\n",
    "1. Subsample each channel to 9x9 pixels using bilinear interpolation -> shape (1, 4, 27, 9, 9)\n",
    "2. Average each modality (S1, S2 L1C, S2 L2A) separately in the channel dimension -> shape (1, 4, 3, 9, 9)\n",
    "3. Flatten into 972 element vector -> shape (972,)\n",
    "4. Append 52 zeros to the end to make the embedding 1024 element long -> shape (1024,)\n",
    "\n",
    "At the end a submission file is created in the expected format for the embed2scale eval.ai challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from scipy.ndimage import zoom\n",
    "from torchvision import transforms\n",
    "\n",
    "from challenge_dataset import E2SChallengeDataset\n",
    "from ssl4eos12_dataset import S2L1C_MEAN, S2L1C_STD, S2L2A_MEAN, S2L2A_STD, S1GRD_MEAN, S1GRD_STD\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities = ['s2l2a', 's2l1c', 's1']\n",
    "\n",
    "# \n",
    "path_to_data = '/path/to/challenge/data/'\n",
    "path_to_output_file = 'path/to/output/file.csv'\n",
    "\n",
    "write_result_to_file = False  # Set to True to trigger saving of the csv at the end.\n",
    "\n",
    "# Create data transformation\n",
    "# Get mean and standard deviations for the modealities in the correct order\n",
    "mean_data = S2L2A_MEAN + S2L1C_MEAN + S1GRD_MEAN\n",
    "std_data = S2L2A_STD + S2L1C_STD + S1GRD_STD\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    # Add additional transformation here\n",
    "    transforms.Normalize(mean=mean_data, std=std_data)\n",
    "])\n",
    "\n",
    "# Note that both E2SChallengeDataset and SSL4EOS12Dataset outputs torch tensors, so there is no need to a ToTensor transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 5537\n",
      "torch.Size([1, 4, 27, 264, 264])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate modalities\n",
    "# dataloader output is {'data': concatenated_data, 'file_name': file_name}\n",
    "# The data has shapes [n_samples, n_seasons, n_channels, height, width] (for concatenated_data [1, 4, 27, 264, 264])\n",
    "\n",
    "dataset_e2s = E2SChallengeDataset(path_to_data, \n",
    "                               modalities = modalities, \n",
    "                               dataset_name='bands', \n",
    "                               transform=data_transform, \n",
    "                               concat=True,\n",
    "                               output_file_name=True\n",
    "                              )\n",
    "\n",
    "# Print dataset length\n",
    "print(f\"Length of train dataset: {len(dataset_e2s)}\")\n",
    "\n",
    "# Print shape of first sample\n",
    "print(dataset_e2s[0]['data'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create submission file\n",
    "\n",
    "In this section, we create a submission by randomly generating embeddings of the correct size.\n",
    "Finally, we create a submission file.\n",
    "\n",
    "We use the E2SChallengeDataset since we can easily get the sample ID (file name) from the this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_format_np_array(arr):\n",
    "    \"\"\"Create string from numpy array formatted as: '[val1, val2, ...]'.\"\"\"\n",
    "    return '[' + ','.join([str(n) for n in arr]) + ']'\n",
    "\n",
    "def create_submission_from_dict(emb_dict):\n",
    "    \"\"\"Assume dictionary has format {hash-id0: embedding0, hash-id1: embedding1, ...}\n",
    "    \"\"\"\n",
    "    df_submission = pd.DataFrame(data=[[k, str_format_np_array(e)] for k, e in emb_dict.items()], \n",
    "                                 columns=['id', 'embedding'], dtype=str)\n",
    "        \n",
    "    return df_submission\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compress by bilinear transform and modality averaging\n",
    "\n",
    "In this section, we create a submission file by processing each sample accordingly:\n",
    "1. Subsampling each channel to 9x9 pixels using bilinear interpolation\n",
    "2. Average each modality (S1, S2 L1C, S2 L2A) in the channel dimension.\n",
    "3. Flatten into 972 element vector\n",
    "4. Append 52 zeros to the end to make the embedding 1024 element long\n",
    "\n",
    "We use the dataloader based on the E2SChallengeDataset since we can easily get the sample ID (file name) from the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(data, file_name, n_missing_numbers):\n",
    "    rescaled = zoom(data, (1, 1, 1, 9/data.shape[3], 9/data.shape[4]), order=1)\n",
    "    # Mean of S2-L2A, S2-L1C and S1 respectively\n",
    "    rescaled = np.concatenate((np.mean(rescaled[:, :, 0:12, :, :], axis=2, keepdims=True), \n",
    "                               np.mean(rescaled[:, :, 12:25, :, :], axis=2, keepdims=True), \n",
    "                               np.mean(rescaled[:, :, 25:, :, :], axis=2, keepdims=True)), \n",
    "                               axis=1)\n",
    "    rescaled = rescaled.flatten()\n",
    "    # append missing values\n",
    "    missing_array = np.array(n_missing_numbers*[0.])\n",
    "    return {'file_name': file_name, 'embedding': np.concatenate((rescaled, missing_array))}\n",
    "\n",
    "\n",
    "def mean_embedding_parallel(dataset, n_missing_numbers, n_workers=4, n_samples=None):\n",
    "    \n",
    "    # Initialize result embeddings\n",
    "    embeddings = {}\n",
    "\n",
    "    # Run embedding in parallel\n",
    "    with ThreadPoolExecutor(max_workers=n_workers) as executor:\n",
    "        futures = []\n",
    "        \n",
    "        for ind, data_file_name in enumerate(dataset):\n",
    "            data = data_file_name['data']\n",
    "            file_name = data_file_name['file_name']\n",
    "            # Submit the batch for processing\n",
    "            future = executor.submit(embed, data, file_name, n_missing_numbers)\n",
    "            futures.append(future)\n",
    "\n",
    "            if (n_samples is not None) and (ind-1 > n_samples):\n",
    "                break\n",
    "        \n",
    "        # Extract results\n",
    "        for future in futures:\n",
    "            res = future.result()\n",
    "            # Compile embeddings\n",
    "            embeddings[res['file_name']] = res['embedding']\n",
    "    return embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of zeros to append at the end\n",
    "n_missing_numbers = 1024-4*3*9*9\n",
    "\n",
    "run_parallel = True\n",
    "\n",
    "if run_parallel:\n",
    "    # Embed data\n",
    "    embeddings = mean_embedding_parallel(dataset_e2s, n_missing_numbers=n_missing_numbers, n_workers=8)\n",
    "else:\n",
    "    embeddings = {}\n",
    "    for ind, data_file_name in enumerate(dataset_e2s):\n",
    "        data = data_file_name['data']\n",
    "        file_name = data_file_name['file_name']\n",
    "\n",
    "        # Embed\n",
    "        rescaled = zoom(data, (1, 1, 1, 9/data.shape[3], 9/data.shape[4]), order=1)\n",
    "        # Mean of S2-L2A, S2-L1C and S1 respectively\n",
    "        rescaled = np.concatenate((np.mean(rescaled[:, :, 0:12, :, :], axis=2, keepdims=True), \n",
    "                                   np.mean(rescaled[:, :, 12:25, :, :], axis=2, keepdims=True), \n",
    "                                   np.mean(rescaled[:, :, 25:, :, :], axis=2, keepdims=True)), \n",
    "                                   axis=1)\n",
    "        rescaled = rescaled.flatten()\n",
    "        # append missing values\n",
    "        missing_array = np.array(n_missing_numbers*[0.])\n",
    "        embeddings[file_name] = np.concatenate((rescaled, missing_array))\n",
    "# Create submission file\n",
    "submission_file = create_submission_from_dict(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of embeddings: 5537\n"
     ]
    }
   ],
   "source": [
    "print('Number of embeddings:', len(submission_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002c11ab0bad1ae6efff695891f5713b95101063eaca5...</td>\n",
       "      <td>[-0.758180558681488,-1.004097580909729,-1.1865...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002c8e787ba871d725f57833996ef31a4d60f370180a9...</td>\n",
       "      <td>[-0.7967846393585205,-0.8520763516426086,-0.73...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0017ed83b4548be10f6e12e84e55b0a57ee6f67eae30ea...</td>\n",
       "      <td>[-0.5252641439437866,-0.9159708023071289,-0.91...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0026f8260255069e3f4b29862368abe752dd7659ab2c0e...</td>\n",
       "      <td>[-0.9750652313232422,-1.2674709558486938,-1.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0031471ca1c1a720c95103d8ca90d2142abd95e27d82f6...</td>\n",
       "      <td>[-1.1343963146209717,-1.3163825273513794,-0.82...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  0002c11ab0bad1ae6efff695891f5713b95101063eaca5...   \n",
       "1  0002c8e787ba871d725f57833996ef31a4d60f370180a9...   \n",
       "2  0017ed83b4548be10f6e12e84e55b0a57ee6f67eae30ea...   \n",
       "3  0026f8260255069e3f4b29862368abe752dd7659ab2c0e...   \n",
       "4  0031471ca1c1a720c95103d8ca90d2142abd95e27d82f6...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.758180558681488,-1.004097580909729,-1.1865...  \n",
       "1  [-0.7967846393585205,-0.8520763516426086,-0.73...  \n",
       "2  [-0.5252641439437866,-0.9159708023071289,-0.91...  \n",
       "3  [-0.9750652313232422,-1.2674709558486938,-1.08...  \n",
       "4  [-1.1343963146209717,-1.3163825273513794,-0.82...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write submission\n",
    "if write_result_to_file:\n",
    "    submission_file.to_csv(path_to_output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
