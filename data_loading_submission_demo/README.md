# Embed2scale challenge submission demo

Here, two jupyter notebooks are provided as a guide how the Embed2Scale Challenge data can be read and how the submission files should be formatted.

In the [demo_load_create_submission.ipynb](https://github.com/DLR-MF-DAS/embed2scale-challenge-supplement/blob/main/data_loading_submission_demo/demo_load_create_submission.ipynb) notebook:

- The challenge data is loaded into torch tensors with two datasets, both a custom for the challenge and the SSL4EO-S12 v1.1 dataset class available [here](https://github.com/DLR-MF-DAS/SSL4EO-S12-v1.1/tree/main). Note however that the SSL4EO-S12 v1.1 dataset assumes that the data for the S2 channels are shifted by +1000, to comply with the latest ESA processing standard. See the SSL4EO-S12 v1.1 [Technical Report](https://arxiv.org/abs/2503.00168) for more details. The challenge data does not include this shift and it is therefore not  identical to the SSL4EO-S12 v1.1. A simple addition of 1000 to the S2 channels of the challenge data makes the two compatible.
- We show how to create a dataloader from the datasets.
- Embeddings are generated by random sampling from a normal distribution.
- A submission file is created in the expected format.
- A function for testing the submission file for common issues is provided.

The [baseline_compression_mean.ipynb](https://github.com/DLR-MF-DAS/embed2scale-challenge-supplement/blob/main/data_loading_submission_demo/baseline_compression_mean.ipynb) notebook is similar but embeds the challenge data by bilinear interpolation and averaging of correlated channels.

The recommended pyhton packages for loading the challenge data are provided in [requirements.txt](https://github.com/DLR-MF-DAS/embed2scale-challenge-supplement/blob/main/data_loading_submission_demo/requirements.txt). Note that only zarr<3.0 is a hard requirement, the remaining is a combination which we have tested. The challenge task data is created with the versions of xarray and zarr stated in requirements.txt.