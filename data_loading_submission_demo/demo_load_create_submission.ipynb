{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f81474bf-e1fc-4fad-8974-84da9b484276",
   "metadata": {},
   "source": [
    "# Embed2Scale challenge demo notebook\n",
    "\n",
    "In this notebook we show two ways of loading the challenge task data; first through our custom challenge dataloader, and then with a dataloader from the updated SSL4EO-S12 V1.1 dataset.\n",
    "\n",
    "We then give an example of how to create a submission file by creating embeddings through random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d53112f-bf63-468c-b41a-ecb41407c652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from challenge_dataset import E2SChallengeDataset, collate_fn\n",
    "from ssl4eos12_dataset import SSL4EOS12Dataset, S2L1C_MEAN, S2L1C_STD, S2L2A_MEAN, S2L2A_STD, S1GRD_MEAN, S1GRD_STD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a12230-d7f4-40ea-bbd0-0f0224a5d0a5",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "490a5301-3dd8-4822-bbc8-1e36c06edb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities = ['s2l2a', 's2l1c', 's1']\n",
    "\n",
    "mean_data = S2L2A_MEAN + S2L1C_MEAN + S1GRD_MEAN\n",
    "std_data = S2L2A_STD + S2L1C_STD + S1GRD_STD\n",
    "\n",
    "path_to_data = '/path/to/challenge/data/'\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=mean_data, std=std_data)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1962b9a-0d1f-40f6-bb0e-6be7a0b47a51",
   "metadata": {},
   "source": [
    "# Load data with custom dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bb85cf8-9f5e-4876-8db5-0fca4f4fdff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 1659\n",
      "Modality s2l2a shape: torch.Size([1, 4, 12, 264, 264])\n",
      "Modality s2l1c shape: torch.Size([1, 4, 13, 264, 264])\n",
      "Modality s1 shape: torch.Size([1, 4, 2, 264, 264])\n"
     ]
    }
   ],
   "source": [
    "# Do not concatenate modalities\n",
    "# Dataloader output is {'data': {'s2l2a': s2l2a_data, 's2l1c': s2l1c_data, 's1': s1_data}, 'file_name': file_name}\n",
    "# The data has shapes [n_samples, n_seasons, n_channels, height, width] (for s2l2a [1, 4, 12, 264, 264])\n",
    "\n",
    "concatenate_modalities = False\n",
    "dataset_e2s = E2SChallengeDataset(path_to_data, \n",
    "                               modalities = modalities, \n",
    "                               dataset_name='bands', \n",
    "                               transform=data_transform, \n",
    "                               concat=concatenate_modalities,\n",
    "                               output_file_name=False\n",
    "                              )\n",
    "\n",
    "# Print dataset length\n",
    "print(f\"Length of train dataset: {len(dataset_e2s)}\")\n",
    "\n",
    "# Print shape of first sample\n",
    "for m, d in dataset_e2s[0].items():\n",
    "    print(f'Modality {m} shape:', d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc36f82a-01d2-4646-8e57-5af449a99b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 1659\n",
      "torch.Size([1, 4, 27, 264, 264])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate modalities\n",
    "# dataloader output is {'data': concatenated_data, 'file_name': file_name}\n",
    "# The data has shapes [n_samples, n_seasons, n_channels, height, width] (for concatenated_data [1, 4, 27, 264, 264])\n",
    "\n",
    "concatenate_modalities = True\n",
    "dataset_e2s = E2SChallengeDataset(path_to_data, \n",
    "                               modalities = modalities, \n",
    "                               dataset_name='bands', \n",
    "                               transform=data_transform, \n",
    "                               concat=concatenate_modalities,\n",
    "                               output_file_name=True\n",
    "                              )\n",
    "\n",
    "# Print dataset length\n",
    "print(f\"Length of train dataset: {len(dataset_e2s)}\")\n",
    "\n",
    "# Print shape of first sample\n",
    "print(dataset_e2s[0]['data'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d195113-f9f8-48cf-87af-6e0008e199e6",
   "metadata": {},
   "source": [
    "# Load with SSL4EOS12 V1.1 dataloader\n",
    "\n",
    "Note that we have modified the code to allow for a different number of samples per zarr files. The challenge task data consists of a single sample per file, while SSL4EO-S12 V1.1 has 64 samples per zarr file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c4f7d65-2f2b-45a6-a093-2ea23f87805d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 1659\n",
      "torch.Size([1, 4, 27, 264, 264])\n"
     ]
    }
   ],
   "source": [
    "dataset_ssl4eo = SSL4EOS12Dataset(\n",
    "    data_dir=path_to_data,\n",
    "    modalities=modalities, # optional, list of modality folders.\n",
    "    transform=data_transform,  # optional, torchvision transforms. Returns tensors if not provided.\n",
    "    concat=True,  # Concatenate all modalities along the band dimension.\n",
    "    single_timestamp=False,  # Load single timestamps rather than time series.\n",
    "    num_batch_samples=1,  # optional, subsample samples in each zarr file.\n",
    "    samples_per_zarr=1\n",
    ")\n",
    "\n",
    "# Print dataset length\n",
    "print(f\"Length of train dataset: {len(dataset_ssl4eo)}\")\n",
    "\n",
    "# Print shape of first sample\n",
    "print(dataset_ssl4eo[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d55ae2a-e93c-4ae1-bd8f-c80df56779c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two datasets' first sample is the same: True\n"
     ]
    }
   ],
   "source": [
    "# Compare the output from the datasets\n",
    "print(\"The two datasets' first sample is the same:\", np.all((dataset_e2s[0]['data'] == dataset_ssl4eo[0]).numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a5e4ad-27e0-4530-81f8-4048d5919b06",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "048b74dc-1e76-4a53-9190-44ab650baad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name 0: 277a989511...\n",
      "File name 1: bcb433a384...\n",
      "torch.Size([2, 4, 27, 264, 264])\n"
     ]
    }
   ],
   "source": [
    "train_loader  = DataLoader(\n",
    "    dataset=dataset_e2s,\n",
    "    batch_size=2,  # Note that each each challenge task zarr file contains a single sample.\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,  # Data needs to be concatenated along sample dimension instead of being stacked,\n",
    ")\n",
    "\n",
    "for ind, data_file_name in enumerate(train_loader):\n",
    "    for find, fn in enumerate(data_file_name['file_name']):\n",
    "        print(f'File name {find}:', fn[0:10] + '...')\n",
    "    print(data_file_name['data'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b02682-b177-4a59-a267-8fb4cfd0f570",
   "metadata": {},
   "source": [
    "# Create submission file\n",
    "\n",
    "In this section, we create a submission by randomly generating embeddings of the correct size.\n",
    "Finally, we create a submission file.\n",
    "\n",
    "We use the E2SChallengeDataset since we can easily get the sample ID (file name) from the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb7435c1-34cd-4dbc-8228-a25302af6cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_format_np_array(arr):\n",
    "    \"\"\"Create string from numpy array formatted as: '[val1, val2, ...]'.\"\"\"\n",
    "    return '[' + ','.join([str(n) for n in arr]) + ']'\n",
    "\n",
    "def create_submission_from_dict(emb_dict):\n",
    "    \"\"\"Assume dictionary has format {hash-id0: embedding0, hash-id1: embedding1, ...}\n",
    "    \"\"\"\n",
    "    df_submission = pd.DataFrame(data=[[k, str_format_np_array(e)] for k, e in emb_dict.items()], \n",
    "                                 columns=['id', 'embedding'], dtype=str)\n",
    "        \n",
    "    return df_submission\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c713d0b8-ddc4-423c-88cf-02c58d1926d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly generate embeddings from normal distribution.\n",
    "\n",
    "create_n_embeddings = 10\n",
    "\n",
    "embedding_dim = 1024\n",
    "embeddings = {}\n",
    "rng = np.random.default_rng(seed=None)\n",
    "for ind, data_file_name in enumerate(train_loader):\n",
    "    # -------------------------\n",
    "    # Do compression magic here\n",
    "    # -------------------------\n",
    "\n",
    "    # Randomly generate embedding from normal distribution\n",
    "    for fn in data_file_name['file_name']:\n",
    "        emb = rng.normal(0, 1, size=(embedding_dim,))\n",
    "        embeddings[fn] = emb\n",
    "\n",
    "    # Stop early in this example\n",
    "    if ind >= create_n_embeddings-1:\n",
    "        break\n",
    "\n",
    "# Create submission file\n",
    "submission_file = create_submission_from_dict(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0ec3b23-537b-4450-87b1-9b2913c68336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4b8e5bda5684f2e7474c66e139275ddf61dce40b1d3377...</td>\n",
       "      <td>[-1.187911937493888,0.8601787852627838,0.42074...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d98a6d88b825cf1925436102c4739cc25ea30014fc9fb2...</td>\n",
       "      <td>[0.21094484112814646,0.4052598312097374,-0.779...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c4dd0056a2f815bf826dc867cc18fe16a66444cdd8e317...</td>\n",
       "      <td>[0.28992485348822905,-0.4125092913214582,0.847...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73d6f99ecabe4cb3afcabd2eb3f9ce39ea4117537c0ca5...</td>\n",
       "      <td>[0.17379557544147067,-0.01019416285788091,1.15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaa7d6eb29e40ae32b716c6e9086b88a179d1f2d9d9624...</td>\n",
       "      <td>[0.0954283316333879,0.6574380779154033,0.18032...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  4b8e5bda5684f2e7474c66e139275ddf61dce40b1d3377...   \n",
       "1  d98a6d88b825cf1925436102c4739cc25ea30014fc9fb2...   \n",
       "2  c4dd0056a2f815bf826dc867cc18fe16a66444cdd8e317...   \n",
       "3  73d6f99ecabe4cb3afcabd2eb3f9ce39ea4117537c0ca5...   \n",
       "4  aaa7d6eb29e40ae32b716c6e9086b88a179d1f2d9d9624...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-1.187911937493888,0.8601787852627838,0.42074...  \n",
       "1  [0.21094484112814646,0.4052598312097374,-0.779...  \n",
       "2  [0.28992485348822905,-0.4125092913214582,0.847...  \n",
       "3  [0.17379557544147067,-0.01019416285788091,1.15...  \n",
       "4  [0.0954283316333879,0.6574380779154033,0.18032...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "591a16c2-d609-428a-b921-41cd32e7c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write submission\n",
    "if False:\n",
    "    submission_file.to_csv('./random_embeddings.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
